DOCKER SWARM:

C N C A
C N P C A


C = CLUSTER
N = NODE
P = POD
C = CONATINER
A = APPLICATION


MASTER NODE COMPONENTS:
1.API Server	: communicates with cluster (command -- > execute -- > op)
2.ETCD 		: db for cluster (stores cluster info)
3.Controllers-manager :  used to control k8s components
4. Schedulers: to schedule pods inside worker node. (depends on hardware)


WORKER NODE COMPONENTS:
1. KUBELET: its an agent (informs everything to master node)
2. KUBEPROXY: it deal with nlw
3. POD: group of containers.

TYPES:
1. SELF-MANAGED CLUSTERS:
A. MINIKUBE (SINGLE NODE)
B. KUBEADM (MULTI NODE)
C. KOPS (MULTI NODE - AUTOMATED)

2. CLODE BASED CLUSTERS:
A. EKS - AWS
B. AKS - AZURE
C. GKS - GOOGLE


MINIKUBE:
It is a tool used to setup single node cluster on K8's. 
It contains API Servers, an ETDC database and container runtime
It is used for development, testing, and experimentation purposes on local. 
Here Master and worker runs on the same machine.
It is a platform Independent.

NOTE: But we dont implement this in real-time

REQUIREMENTS:
2 CPUs or more
2GB of free memory
20GB of free disk space
Internet connection
Container or virtual machine manager, such as: Docker.

SETUP:
sudo apt update -y
sudo apt upgrade -y
sudo apt install curl wget apt-transport-https -y
sudo curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo mv minikube-linux-amd64 /usr/local/bin/minikube
sudo chmod +x /usr/local/bin/minikube
sudo minikube version
sudo curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
sudo echo "$(cat kubectl.sha256) kubectl" | sha256sum --check
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
sudo minikube start --driver=docker --force


PODS:
It is a smallest unit of deployment in K8's.
It is a group of containers.
Pods are ephemeral (short living objects)
Mostly we can use single container inside a pod but if we required, we can create multiple containers inside a same pod.
when we create a pod, containers inside pods can share the same network namespace, and can share the same storage volumes .
While creating pod, we must specify the image, along with any necessary configuration and resource limits.
K8's cannot communicate with containers, they can communicate with only pods.

 We can create this pod in two ways, 
1. Imperative(command) 
2. Declarative (Manifest file)


IMPERATIVE: 
kubectl run pod1 --image rahamshaik/paytmtrain:latest
kubectl get po/pod/pods
kubectl get po/pod/pods -o wide
kubectl describe pod pod1
kubectl delete pod pod1

Declarative:
vim abc.yml

apiVersion: v1
kind: Pod
metadata:
   name: pod1
spec:
  containers:
    - image: nginx
      name: cont1

kubectl create -f abc.yml
kubectl get po/pod/pods
kubectl get po/pod/pods -o wide
kubectl describe pod pod1
kubectl delete pod pod1

REPLICASET:

it will create same pod of multiple replicas.
if we delete one pod it will create automatically.
we can distribute the load also.

vim abc.yml

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  labels:
    app: movies
  name: movies-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: movies
  template:
    metadata:
      labels:
        app: movies
    spec:
      containers:
        - name: cont1
          image: abduljavvadkhan786/movies:latest

kubectl create -f abc.yml

kubectl get rs
kubectl get rs -o wide
kubectl describe rs movies-rs
kubectl edit rs/movies-rs
kubectl delete rs movies-rs


SCALE:
SCALE-IN : TO INCREASE STRENGTH OF PODS
kubectl scale rs/movies-rs --replicas=20

SCALE-OUT : TO DECREASE STRENGTH OF PODS
kubectl scale rs/movies-rs --replicas=5

SCALING FOLLOWS LIFO PATTERN:
LIFO: LAST IN FIRST OUT
the pod which is created will be deleted first automatically when we scale out.


DRAW BACK:
it cant update the applicationm (rollin and rollout will not work)

DEPLOYMENT:
in k8s deployment will be highlevel object
it will do all operations like RS.
it will do roll back which cannot be done in rs.


DEPLOYMENT -- > REPLICASET -- > POD

vim abc.yml

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: movies
  name: movies-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: movies
  template:
    metadata:
      labels:
        app: movies
    spec:
      containers:
        - name: cont1
          image: abduljavvadkhan786/movies:latest

kubectl create -f abc.yml

kubectl get deploy
kubectl get deploy -o wide
kubectl describe deploy movies-rs
kubectl edit deploy/movies-rs
kubectl delete deploy movies-rs


SCALE:
SCALE-IN : TO INCREASE STRENGTH OF PODS
kubectl scale rs/movies-rs --replicas=20

SCALE-OUT : TO DECREASE STRENGTH OF PODS
kubectl scale rs/movies-rs --replicas=5

kubectl api-resources

HISTORY:

 1  vim minikube.sh
    2  sh minikube.sh
    3  kubectl run pod1 --image abduljavvadkhan786/train:latest
    4  kubectl get po
    5  kubectl delete pod pod1
    6  vim pod.yml
    7  kubectl get po
    8  kubectl create -f pod.yml
    9  cat pod.yml
   10  vim pod.yml
   11  kubectl create -f pod.yml
   12  kubectl get rs
   13  kubectl get po
   14  kubectl get po -o wide
   15  kubectl get po --show-labels
   16  kubectl describe rs movies-rs
   17  kubectl get po
   18  kubectl delete pod movies-rs-8jvrs
   19  kubectl get po
   20  kubectl delete pod movies-rs-wz7l8
   21  kubectl get po
   22  kubectl scale rs/movies-rs --replicas=10
   23  kubectl get po
   24  kubectl scale rs/movies-rs --replicas=20
   25  kubectl get po
   26  kubectl scale rs/movies-rs --replicas=5
   27  kubectl get po
   28  cat pod.yml
   29  kubectl desribe rs movies-rs
   30  kubectl describe rs movies-rs
   31  kubectl edit rs/movies-rs
   32  kubectl describe rs movies-rs
   33  kubectl get po
   34  kubectl describe pod movies-rs-9w5wk | grep -i image
   35  kubectl describe pod movies-rs-bdjdw | grep -i image
   36  kubectl describe pod movies-rs-gz2xd | grep -i image
   37  kubectl delete rs movies-rs
   38  kubectl get po
   39  vim pod.yml
   40  kubectl get po
   41  kubectl create -f pod.yml
   42  kubectl get deploy
   43  kubectl get rs
   44  kubectl get po
   45  kubectl edit deploy/movies-rs
   46  kubectl get po
   47  kubectl describe pod movies-rs-546cff74d-5dpcd }| grep -i image
   48  kubectl describe pod movies-rs-546cff74d-ldbxj | grep -i image
   49  kubectl describe pod movies-rs-546cff74d-lz9pb | grep -i image
   50  kubectl edit deploy/movies-rs
   51  kubectl get po
   52  kubectl describe pod movies-rs-6764d9ccff-645qq | grep -i image
   53  kubectl describe pod movies-rs-6764d9ccff-dj4db | grep -i image
   54  kubectl describe pod movies-rs-6764d9ccff-qdksw | grep -i image
   55  kubectl scale deploy/movies-rs --replicas=10
   56  kubectl get po
   57  kubectl delete deploy movies-rs
   58  kubectl api-resources
   59  cat minikube.sh
   60  history
root@ip-172-31-43-3:~#

=========================================================================

KOPS:
INFRASTRUCTURE: Resources used to run our application on cloud.
EX: Ec2, VPC, ALB, -------------


Minikube -- > single node cluster
All the pods on single node 
kOps, also known as Kubernetes operations.
it is an open-source tool that helps you create, destroy, upgrade, and maintain a highly available, production-grade Kubernetes cluster. 
Depending on the requirement, kOps can also provide cloud infrastructure.
kOps is mostly used in deploying AWS and GCE Kubernetes clusters. 
But officially, the tool only supports AWS. Support for other cloud providers (such as DigitalOcean, GCP, and OpenStack) are in the beta stage.


ADVANTAGES:
•	Automates the provisioning of AWS and GCE Kubernetes clusters
•	Deploys highly available Kubernetes masters
•	Supports rolling cluster updates
•	Autocompletion of commands in the command line
•	Generates Terraform and CloudFormation configurations
•	Manages cluster add-ons.
•	Supports state-sync model for dry-runs and automatic idempotency
•	Creates instance groups to support heterogeneous clusters

ALTERNATIVES:
Amazon EKS , MINIKUBE, KUBEADM, RANCHER, TERRAFORM.


STEP-1: GIVING PERMISSIONS
IAM -- > USER -- > CREATE USER -- > NAME: KOPS -- > Attach Polocies Directly -- > AdministratorAccess -- > NEXT -- > CREATE USER
USER -- > SECURTITY CREDENTIALS -- > CREATE ACCESS KEYS -- > CLI -- > CHECKBOX -- >  CREATE ACCESS KEYS -- > DOWNLOAD 

aws configure (run this command on server)

SETP-2: INSTALL KUBECTL AND KOPS

curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl
mv kubectl /usr/local/bin/kubectl
mv kops-linux-amd64 /usr/local/bin/kops

vim .bashrc
export PATH=$PATH:/usr/local/bin/  -- > save and exit
source .bashrc

SETP-3: CREATING BUCKET 
aws s3api create-bucket --bucket cloudanddevopsbyraham0078.k8s.local --region us-east-1
aws s3api put-bucket-versioning --bucket cloudanddevopsbyraham007.k8s.local --region us-east-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://cloudanddevopsbyraham0078.k8s.local

SETP-4: CREATING THE CLUSTER
kops create cluster --name rahams.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --node-count=2 --node-size t2.micro
kops update cluster --name rahams.k8s.local --yes --admin


Suggestions:
 * list clusters with: kops get cluster
 * edit this cluster with: kops edit cluster rahams.k8s.local
 * edit your node instance group: kops edit ig --name=rahams.k8s.local nodes-us-east-1a
 * edit your master instance group: kops edit ig --name=rahams.k8s.local master-us-east-1a


ADMIN ACTIVITIES:
To scale the worker nodes:
kops edit ig --name=rahams.k8s.local nodes-us-east-1a
kops update cluster --name rahams.k8s.local --yes --admin 
kops rolling-update cluster --yes

kubectl describe node node_id
kops delete cluster --name rahams.k8s.local --yes

HISTORY:

  1  aws configure
    2  curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd6                                                                                                                                                                                                       4/kubectl"
    3  wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
    4  chmod +x kops-linux-amd64 kubectl
    5  mv kubectl /usr/local/bin/kubectl
    6  mv kops-linux-amd64 /usr/local/bin/kops
    7  ls -al
    8  vim .bashrc
    9  source .bashrc
   10  kops version
   11  kubectl version
   12  aws s3api create-bucket --bucket cloudanddevopsbyraham0078local --region us-east-1                                                                                                                                                                                                     nfiguration Status=Enabled
   17  aws s3api put-bucket-versioning --bucket cloudanddevopsbyraham0078local --region us-east-1 --versioni                                                                                                                                                                                                       ng-configuration Status=Enabled
   18  export KOPS_STATE_STORE=s3://cloudanddevopsbyraham0078local
   19  kops create cluster --name rahams.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medi                                                                                                                                                                                                       um --node-count=2 --node-size t2.micro
   20  kops update cluster --name rahams.k8s.local --yes --admin
   21  kops validate cluster --wait 10m
   22  kubectl get no
   23  kops edit cluster rahams.k8s.local
   24  kubectl get no
   25  kops edit ig --name=rahams.k8s.local nodes-us-east-1a
   26  kops update cluster --name rahams.k8s.local --yes
   27  kops rolling-update cluster
   28  kubectl get no
   29  kops edit ig --name=rahams.k8s.local nodes-us-east-1a
   30  kops update cluster --name rahams.k8s.local --yes
   31  kops rolling-update cluster
   32  kops edit ig --name=rahams.k8s.local master-us-east-1a
   33  kops update cluster --name rahams.k8s.local --yes
   34  kops rolling-update cluster
   35  kops delete cluster --name rahams.k8s.local --yes
   36  history

==============================================

KUBECOLOR:

wget https://github.com/hidetatz/kubecolor/releases/download/v0.0.25/kubecolor_0.0.25_Linux_x86_64.tar.gz
tar -zxvf kubecolor_0.0.25_Linux_x86_64.tar.gz
./kubecolor
chmod +x kubecolor
mv kubecolor /usr/local/bin/
kubecolor get po


NAMESPACES:

NAMESPACE: It is used to divide the cluster to multiple teams on real time.
it is used to isolate the env.

CLUSTER: HOUSE
NAMESPACES: ROOM

Each namespace is isolated.
if your are room-1 are you able to see room-2.
we can't access the objects from one namespace to another namespace.


TYPES:

default           : Is the default namespace, all objects will create here only
kube-node-lease   : it will store object which is taken from one namespace to another.
kube-public	  : all the public objects will store here.      
kube-system 	  : default k8s will create some objects, those are storing on this ns.

kubectl get pod -n kube-system	: to list all pods in kube-system namespace
kubectl get pod -n default	: to list all pods in default namespace
kubectl get pod -n kube-public	: to list all pods in kube-public namespace
kubectl get po -A		: to list all pods in all namespaces

kubectl create ns dev	: to create namespace
kubectl config set-context --current --namespace=dev : to switch to the namespace
kubectl config view --minify | grep namespace : to see current namespace
kubectl run dev1 --image abduljavvadkhan786/movies:latest
kubectl run dev2 --image abduljavvadkhan786/movies:latest
kubectl run dev3 --image abduljavvadkhan786/movies:latest
kubectl config set-context --current --namespace=test : to switch to the namespace
kubectl config view --minify | grep namespace : to see current namespace
kubectl get po
kubectl get po -n dev
kubectl delete po dev1 -n dev
kubectl delete ns dev	: to delete namespace
kubectl delete pod --all: to delete all pods


NOTE: By deleting  the ns all objects also gets deleted.
in real time we use rbac concept to restrict the access from one namespace to another.
so users cant access/delete ns, because of the restriction we provide.
we create roles and rolebind for the users.


SERVICE: It is used to expose the application in k8s.

TYPES:
1. CLUSTERIP: It will work inside the cluster.
it will not expose to outer world.

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: rahamshaik/moviespaytm:latest
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: sv1
spec:
  type: ClusterIP
  selector:
    app: swiggy
  ports:
    - port: 80

DRAWBACK:
We cannot use app outside.

2. NODEPORT: It will expose our application in a particular port.
Range: 30000 - 32767 (in sg we need to give all traffic)

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: rahamshaik/trainservice:latest
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: abc
spec:
  type: NodePort
  selector:
    app: swiggy
  ports:
    - port: 80
      targetPort: 80
      nodePort: 31111

NOTE: UPDATE THE SG (REMOVE OLD TRAFFIC AND GIVE ALL TRAFFIC & SSH)
DRAWBACK:
PORT RESTRICTION.

3. LOADBALACER: It will expose our app and distribute load blw pods.

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: rahamshaik/trainservice:latest
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: abc
spec:
  type: LoadBalancer
  selector:
    app: swiggy
  ports:
    - port: 80
      targetPort: 80


history:
1  vim kops.sh
    2  vim .bashrc
    3  source .bash
    4  source .bashrc
    5  sh kops.sh
    6  kops validate cluster --wait 10m
    7  cat kops.sh
    8  export KOPS_STATE_STORE=s3://cloudanddevopsbyraham007899.k8s.local
    9  kops validate cluster --wait 10m
   10  kubectl get ns
   11  kubectl run pod1 --image nginx
   12  kubectl describe pod pod1
   13  kubectl get po
   14  kubectl get po -n kube-system
   15  kubectl get po
   16  kubectl create ns dev
   17  kubectl get ns
   18  kubectl config set-context --current -n=dev
   19  kubectl config set-context --current --namespace=dev
   20  kubectl config view --minify
   21  kubectl get po
   22  kubectl run pod1 --image abduljavvadkhan786/movies:latest
   23  kubectl delete pod pod1
   24  kubectl run dev1 --image abduljavvadkhan786/movies:latest
   25  kubectl run dev2 --image abduljavvadkhan786/movies:latest
   26  kubectl run dev3 --image abduljavvadkhan786/movies:latest
   27  kubectl get po
   28  kubectl create ns test
   29  kubectl config set-context --current --namespace=test
   30  kubectl config view
   31  kubectl get po
   32  kubectl get po -n dev
   33  kubectl delete po -n dev
   34  kubectl delete po dev1 -n dev
   35  kubectl delete ns dev
   36  kubectl delete po --all
   37  kubectl config set-context --current --namespace=default
   38  kubectl delete po --all
   39  vim abc.yml
   40  kubectl get svc
   41  kubectl api-resources
   42  kubectl get svc
   43  kubectl create -f abc.yml
   44  kubectl get svc,deploy
   45  kubectl delete -f abc.yml
   46  vim abc.yml
   47  kubectl create -f abc.yml
   48  kubectl get svc,deploy
   49  kubectl get po -o wide
   50  vim abc.yml
   51  kubectl apply -f abc.yml
   52  kubectl get svc,deploy
   53  kubectl create -f abc.yml
   54  kubectl delete -f abc.yml
   55  kubectl create -f abc.yml
   56  kubectl get svc,deploy
   57  kubectl delete -f abc.yml
   58  vim abc.yml
   59  kubectl create -f abc.yml
   60  kubectl get svc,deploy
   61  wget https://github.com/hidetatz/kubecolor/releases/download/v0.0.25/kubecolor_0.0.25_Lin                                                                                                                                                                                                                   ux_x86_64.tar.gz
   62  tar -zxvf kubecolor_0.0.25_Linux_x86_64.tar.gz
   63  ./kubecolor
   64  chmod +x kubecolor
   65  mv kubecolor /usr/local/bin/
   66  kubecolor get po
   67  kubecolor get svc
   68  kubecolor get ns
   69  history

